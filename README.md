# Banco XYZ - Migraci√≥n de Procesos Batch con Spring Batch

## üöÄ Objetivo
Modernizar el sistema batch legacy del Banco XYZ usando Spring Batch, con procesamiento paralelo, manejo robusto de errores y trazabilidad de resultados.

## üìÅ Estructura del Proyecto

- `src/main/java/com/duoc/batch/`
  - `config/BatchConfiguration.java`: Configuraci√≥n de jobs, steps, particiones y paralelismo.
  - `model/`: Modelos de datos (`Transaccion`, `CuentaInteres`, `CuentaAnual`).
  - `processor/`: Validaci√≥n y transformaci√≥n de datos.
  - `advanced/`: Listeners, skip policies y l√≥gica avanzada de errores.
  - `BatchApplication.java`: Main Spring Boot.
- `src/main/resources/`
  - `data/`: Archivos CSV de entrada.
  - `application.properties`: Configuraci√≥n de base de datos y batch.
  - `data.sql`: Limpieza de tablas antes de cada corrida.
- `pom.xml`: Dependencias Maven.

## üõ†Ô∏è Prerrequisitos

- Java 21+
- Maven 3.5.4+
- Oracle Database

## ‚öôÔ∏è Configuraci√≥n Inicial

1. Crea la base de datos y las tablas necesarias:
    ```sql
    CREATE TABLE transacciones (
        id VARCHAR(255) PRIMARY KEY,
        fecha DATE,
        monto DOUBLE PRECISION,
        tipo VARCHAR(255)
    );
    CREATE TABLE cuentas (
        cuenta_id VARCHAR(255) PRIMARY KEY,
        nombre VARCHAR(255),
        saldo DOUBLE PRECISION,
        edad INT,
        tipo VARCHAR(255)
    );
    ```
2. Configura `src/main/resources/application.properties` con tus credenciales Oracle.
3. El archivo `data.sql` limpia las tablas autom√°ticamente al iniciar la app.

## üèÉ Ejecuci√≥n de Jobs

Compila el proyecto:
```bash
mvn clean install
```

Ejecuta un job espec√≠fico:

| Job                        | Comando                                                                 |
|----------------------------|-------------------------------------------------------------------------|
| Reporte de Transacciones   | `java -jar target/batch-0.0.1-SNAPSHOT.jar spring.batch.job.name=importTransaccionJob` |
| C√°lculo de Intereses       | `java -jar target/batch-0.0.1-SNAPSHOT.jar spring.batch.job.name=calculoInteresJob`    |
| Estado de Cuenta Anual     | `java -jar target/batch-0.0.1-SNAPSHOT.jar spring.batch.job.name=generacionEstadoCuentaJob` |

## üìä Ejemplo de Archivos de Entrada

`data/transacciones.csv`:
```
id,fecha,monto,tipo
1,2023-01-01,1000,credito
2,2023-01-02,500,debito
...etc
```

## üì¶ Resultados y Evidencia

- **importTransaccionJob**: Ver tabla `transacciones` en Oracle.
- **calculoInteresJob**: Ver tabla `cuentas` en Oracle.
- **generacionEstadoCuentaJob**: Ver archivo `target/estado_cuenta_anual.txt`.


## üìù Logs, Monitoreo y Cierre del Proceso

- Todos los procesos y errores se registran usando SLF4J/Logback.
- Los archivos de errores por partici√≥n se generan en `target/` (ej: `transacciones_errores_0.csv`).
- Los logs muestran inicio, fin y resumen de cada job y step.
- **Cierre autom√°tico del proceso:** El m√©todo `main` de la aplicaci√≥n utiliza `SpringApplication.exit(ctx); System.exit(exitCode);` para forzar el cierre de la JVM al finalizar el job. En este proyecto, debido a la forma en que est√° programado, fue necesario aplicar esta soluci√≥n porque algunos threads de pools de ejecuci√≥n, conexiones JDBC (como `Batch-Thread-1`, `HikariPool-1:housekeeper`, `OJDBC-WORKER-THREAD-1`, etc.) y recursos internos pueden quedar abiertos tras finalizar el job, impidiendo que la JVM termine sola. El cierre forzado garantiza que el proceso finalice correctamente y puedas ejecutar otros jobs en secuencia sin problemas.

## üèóÔ∏è Arquitectura y Dise√±o

Este proyecto utiliza una arquitectura basada en **Spring Batch** para el procesamiento de datos batch, con √©nfasis en la escalabilidad, robustez y trazabilidad. La arquitectura se divide en capas:

- **Capa de Configuraci√≥n (`config/`)**: Define jobs, steps, particionadores y beans de Spring. Utiliza anotaciones como `@Bean` y `@StepScope` para inyecci√≥n de dependencias y alcance limitado.
- **Capa de Modelo (`model/`)**: Representa las entidades de datos (Transaccion, CuentaInteres, CuentaAnual) con validaciones b√°sicas.
- **Capa de Procesamiento (`processor/`)**: Contiene l√≥gica de transformaci√≥n y validaci√≥n de datos, implementando `ItemProcessor` para filtrar o transformar items.
- **Capa Avanzada (`advanced/`)**: Incluye listeners para monitoreo, skip policies para manejo de errores, y l√≥gica personalizada para escenarios complejos.

El dise√±o incorpora **particionamiento** para dividir grandes vol√∫menes de datos en chunks procesables en paralelo, mejorando el rendimiento. Los errores se manejan a nivel de item y chunk, con archivos de error generados por partici√≥n para facilitar la depuraci√≥n.

## üìã Explicaci√≥n de Jobs

### importTransaccionJob
- **Funci√≥n**: Importa transacciones desde un archivo CSV, valida los datos (fecha, monto, tipo) y los inserta en la tabla `transacciones` de Oracle.
- **Motivo**: Automatizar la carga masiva de transacciones bancarias, asegurando integridad de datos y manejo de errores.
- **Componentes**: Usa `FlatFileItemReader` para leer CSV, `TransaccionItemProcessor` para validaci√≥n, `JdbcBatchItemWriter` para escritura en DB, y listeners para errores.

### calculoInteresJob
- **Funci√≥n**: Calcula intereses sobre cuentas desde un CSV, actualiza o inserta en la tabla `cuentas` usando MERGE.
- **Motivo**: Procesar c√°lculos financieros peri√≥dicos, con paralelismo para manejar grandes vol√∫menes.
- **Componentes**: Similar al job de transacciones, pero con `CuentaInteresItemProcessor` y escritura condicional en DB.

### generacionEstadoCuentaJob
- **Funci√≥n**: Genera un archivo √∫nico `estado_cuenta_anual.csv` con el estado de cuentas anuales, procesando datos desde CSV.
- **Motivo**: Crear reportes consolidados de estados de cuenta, con un solo archivo de salida para simplicidad, mientras que los errores se particionan.
- **Componentes**: Usa `FlatFileItemWriter` con `append(true)` para acumular en un solo archivo, y error writers por partici√≥n.

## üîß Componentes Clave

- **Readers**: `FlatFileItemReader` para leer CSVs con mapeo a modelos. Configurados con `@StepScope` para particionamiento.
- **Processors**: Implementan `ItemProcessor` para validar y transformar datos. Por ejemplo, `TransaccionItemProcessor` lanza excepciones para datos inv√°lidos o retorna `null` para filtrar.
- **Writers**: `JdbcBatchItemWriter` para DB, `FlatFileItemWriter` para archivos. Los writers de error son `@StepScope` con `partitionId` para archivos separados.
- **Listeners**: `SkipListener` para manejar skips, `StepExecutionListener` para archivos de error. Proporcionan trazabilidad.
- **Skip Policies**: `CustomSkipPolicy` define cu√°ndo saltar items (ej: excepciones de validaci√≥n).
- **Partitioners**: `RangePartitioner` divide archivos en rangos para procesamiento paralelo.

## üéØ Motivos de Decisiones de Dise√±o

- **Particionamiento**: Divide datos en chunks para paralelismo, mejorando rendimiento en archivos grandes. Usa hasta 6 hilos configurables.
- **Manejo de Errores**: Skip policies y listeners permiten continuar procesamiento ante errores, generando archivos de error por partici√≥n para an√°lisis.
- **@StepScope**: Limita el alcance de beans a cada step/partici√≥n, evitando conflictos en entornos paralelos.
- **Logging Avanzado**: Logs expl√≠citos en writers para auditar inserts, compensando limitaciones de Spring Batch en particionamiento.
- **Cierre Forzado**: `System.exit()` asegura liberaci√≥n de recursos, necesario por threads persistentes en JDBC/Hikari.
- **Archivos √önicos vs. Particionados**: Para salidas principales (ej: estado_cuenta_anual), un archivo √∫nico simplifica; para errores, particionados facilitan depuraci√≥n.

## ‚öôÔ∏è Configuraciones Avanzadas

- **application.properties**: Configura DB (URL, usuario, contrase√±a), batch (chunk size, grid size), y logging.
- **pom.xml**: Incluye dependencias como `spring-boot-starter-batch`, `ojdbc8` para Oracle, y plugins para Maven.
- **data.sql**: Script para limpiar tablas antes de corridas, evitando duplicados.
- **TaskExecutor**: Configurado con `ThreadPoolTaskExecutor` para paralelismo controlado, con `corePoolSize=6` y `maxPoolSize=10`.

## üõ†Ô∏è Troubleshooting Avanzado

- **Archivos de Error Vac√≠os**: Verifica permisos de escritura en `output/`. Aseg√∫rate de que `@StepScope` est√© en writers de error.
- **PartitionId Null**: Puede ocurrir si el partitioner no configura correctamente el contexto. Verifica `RangePartitioner` y `@Value("#{stepExecutionContext['partitionId']}")`.
- **OutOfMemoryError**: Reduce `chunkSize` o `gridSize` en `BatchConfiguration` para archivos muy grandes.
- **Deadlocks en DB**: Aseg√∫rate de que transacciones sean cortas; usa `PlatformTransactionManager` para rollback.
- **Logs No Aparecen**: Verifica configuraci√≥n de SLF4J/Logback en `application.properties`.
- **Paralelismo No Funciona**: Confirma que `TaskExecutor` est√© configurado y `gridSize > 1`.

  # Notas sobre el tracking de registros escritos en jobs particionados

En este proyecto, al usar particionamiento con Spring Batch, se observ√≥ que el contador interno de registros escritos (`writeCount`) en los steps workers y en el resumen del job puede permanecer en 0, incluso cuando los datos v√°lidos s√≠ se insertan correctamente en la base de datos.

Esto ocurre porque, en escenarios avanzados de particionamiento y wiring personalizado, el tracking interno de Spring Batch no siempre refleja los inserts reales, aunque el procesamiento y la escritura funcionen correctamente.

**¬øC√≥mo se valid√≥ la correcta inserci√≥n?**

- Se agreg√≥ un log expl√≠cito en el writer (`loggingTransaccionWriter`) que imprime en consola cada vez que se escribe un chunk y los IDs de las transacciones insertadas.
- Se comprob√≥ que los IDs mostrados en el log coinciden exactamente con los datos insertados en la base de datos.

**¬øPor qu√© se insert√≥ el log en el writer?**

- Para tener una trazabilidad real y confiable de los registros escritos por cada partici√≥n, independientemente del contador interno de Spring Batch.
- Esto permite validar que el procesamiento y la escritura son correctos, aunque el resumen del job muestre 'Total escritos (v√°lidos): 0'.

**Conclusi√≥n:**

El job funciona correctamente y cumple con los requerimientos de procesamiento, validaci√≥n y escritura en la base de datos. El log en el writer es la fuente confiable para auditar los registros escritos en escenarios de particionamiento avanzado.

---
Desarrollado por luciano1633 para Banco XYZ.
